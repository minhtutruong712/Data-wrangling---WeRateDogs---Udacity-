{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import requests as re\n",
    "import os\n",
    "import tweepy as tp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read WeRateDogs Twitter archive file on hand\n",
    "twitter_archive = pd.read_csv(r'C:\\Users\\trtu2001\\Desktop\\Udacity - Data Wrangling\\twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write file tsv containing images\n",
    "path = os.getcwd() # get the current path\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = re.get(url)\n",
    "if not os.path.exists(url.split('/')[-1]):\n",
    "    with open(os.path.join(path, url.split('/')[-1]), mode = 'wb') as file:\n",
    "        file.write(response.content)\n",
    "        \n",
    "# read image prediction tsv file into dataframe\n",
    "image_prediction = pd.read_csv(r'C:\\Users\\trtu2001\\Desktop\\Udacity - Data Wrangling\\image-predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# omit keys from submission to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'trwzMEOtXrAFiyJRW2hZVqA5c'\n",
    "consumer_secret = 'JVI4rTTIyccfAABQDjprAGnpsQ1CEyIWaNfXSTfVei9V5mxVLv'\n",
    "access_token = '1576941143874760704-dhdfW9p2fDUxO2bkxKGOBnTAa2mxZZ'\n",
    "access_secret = 'IIuy2YQxQheg8zG3HN9C9czHAenjpn7rC7AALpctel1ov'\n",
    "\n",
    "auth = tp.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tp.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 488\n",
      "Rate limit reached. Sleeping for: 531\n"
     ]
    }
   ],
   "source": [
    "# avoid gather data again in case the file is ready\n",
    "if not os.path.exists('tweet_json.txt'):\n",
    "    # list twitter id into array to query Twitter API for additional information\n",
    "    list_id = twitter_archive.tweet_id.values\n",
    "\n",
    "    # store each tweet's entire set of JSON data in a file called tweet_json.txt file\n",
    "    fails_dict = {}\n",
    "    with open('tweet_json.txt', 'w', encoding = 'utf-8') as f: \n",
    "        for id in list_id: \n",
    "            try: \n",
    "                tweet = api.get_status(id, tweet_mode='extended')\n",
    "                json.dump(tweet._json, f)\n",
    "                f.write('\\n')\n",
    "            except tp.errors.TweepyException as e: \n",
    "                fails_dict[id] = e\n",
    "                pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tweet_json.txt line by line into dataframe \n",
    "# with tweet ID, retweet count, favorite count\n",
    "df_list = []\n",
    "with open('tweet_json.txt', 'r', encoding = 'utf-8') as f:\n",
    "    for count, line in enumerate(f): \n",
    "        tweet_id = json.loads(line)['id']\n",
    "        retweet_count = json.loads(line)['retweet_count']\n",
    "        favorite_count = json.loads(line)['favorite_count']\n",
    "        df_list.append({'tweet_id': tweet_id, \n",
    "        'retweet_count': retweet_count, \n",
    "        'favorite_count': favorite_count})\n",
    "\n",
    "tweet_api = pd.DataFrame(df_list, columns = ['tweet_id', 'retweet_count', 'favorite_count'])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change datatype timestamp from string into datetime to exclude tweets beyond August 1st, 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   int64  \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check datatype of timestamp column\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2017-08-01 16:23:56 +0000\n",
       "1       2017-08-01 00:17:27 +0000\n",
       "2       2017-07-31 00:18:03 +0000\n",
       "3       2017-07-30 15:58:51 +0000\n",
       "4       2017-07-29 16:00:24 +0000\n",
       "                  ...            \n",
       "2351    2015-11-16 00:24:50 +0000\n",
       "2352    2015-11-16 00:04:52 +0000\n",
       "2353    2015-11-15 23:21:54 +0000\n",
       "2354    2015-11-15 23:05:30 +0000\n",
       "2355    2015-11-15 22:32:08 +0000\n",
       "Name: timestamp, Length: 2356, dtype: object"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data format\n",
    "twitter_archive.timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rating denominator is equal to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>835246439529840640</td>\n",
       "      <td>8.352460e+17</td>\n",
       "      <td>26259576.0</td>\n",
       "      <td>2017-02-24 21:54:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>@jonnysun @Lin_Manuel ok jomny I know you're e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "313  835246439529840640           8.352460e+17           26259576.0   \n",
       "\n",
       "                     timestamp  \\\n",
       "313  2017-02-24 21:54:03 +0000   \n",
       "\n",
       "                                                source  \\\n",
       "313  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                  text  retweeted_status_id  \\\n",
       "313  @jonnysun @Lin_Manuel ok jomny I know you're e...                  NaN   \n",
       "\n",
       "     retweeted_status_user_id retweeted_status_timestamp expanded_urls  \\\n",
       "313                       NaN                        NaN           NaN   \n",
       "\n",
       "     rating_numerator  rating_denominator  name doggo floofer pupper puppo  \n",
       "313               960                   0  None  None    None   None  None  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive[twitter_archive.rating_denominator == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Column expanded_urls has more 2 links, one in which is not twitter link or duplicated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86      https://twitter.com/dog_rates/status/875747767...\n",
       "1918    https://twitter.com/dog_rates/status/674271431...\n",
       "1849    https://twitter.com/dog_rates/status/675781562...\n",
       "2064    https://twitter.com/dog_rates/status/671154572...\n",
       "98      https://www.gofundme.com/help-my-baby-sierra-g...\n",
       "1175    https://twitter.com/dog_rates/status/720043174...\n",
       "698     https://twitter.com/dog_rates/status/786363235...\n",
       "2184    https://twitter.com/dog_rates/status/668988183...\n",
       "2119    https://twitter.com/dog_rates/status/670417414...\n",
       "2208    https://twitter.com/dog_rates/status/668625577...\n",
       "Name: expanded_urls, dtype: object"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly check the data format in expanded_urls\n",
    "twitter_archive.expanded_urls.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.gofundme.com/help-my-baby-sierra-get-better,https://twitter.com/dog_rates/status/873213775632977920/photo/1,https://twitter.com/dog_rates/status/873213775632977920/photo/1'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check random data to see expanded_urls\n",
    "twitter_archive.at[98, 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Column name contains wrong names, convert None into NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262       Tater\n",
       "2045         Jax\n",
       "430        Flash\n",
       "2343        None\n",
       "2207      Timofy\n",
       "1980    Chuckles\n",
       "1231       Lance\n",
       "1815         the\n",
       "1926     Stanley\n",
       "1083      Bayley\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special character is not the right name is: a, the, ...\n",
    "twitter_archive.name.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tweet_ID = 740373189193256964 the dog has the rating is 14/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1'"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 740373189193256964].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Tweet_ID = 810984652412424192 the dog does not have the rating yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.gofundme.com/sams-smile,https://twitter.com/dog_rates/status/810984652412424192/photo/1'"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "# this tweet_id is not displayed -  24/7 not the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 810984652412424192].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Tweet_ID = 722974582966214656 the dog has the rating is 13/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/722974582966214656/photo/1'"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 722974582966214656].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Tweet_ID = 666287406224695296 the dog has the rating is 9/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/666287406224695296/photo/1'"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 666287406224695296].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Tweet_ID = 775096608509886464 does not exist, it is a duplication of Tweet_ID = 740373189193256964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1'"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the id in the url is 740373189193256964 not 775096608509886464\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 775096608509886464].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove data in twitter-archive-enhancement.csv for matching with the image_prediction.tsv - only data not beyond August 1st, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Match image prediction columns in image_prediction.tsv to define dog tweet_id and columns retweet count and favorite count in tweet_api for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1.\n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "twitter_archive_cp = twitter_archive.copy()\n",
    "image_prediction_cp = image_prediction.copy()\n",
    "tweet_api_cp = tweet_api.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Change datatype timestamp from string into datetime to exclude tweets beyond August 1st, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype\n",
    "twitter_archive_cp.timestamp = pd.to_datetime(twitter_archive_cp.timestamp)\n",
    "\n",
    "# exclude data with timestamp beyond August 1st, 2017\n",
    "twitter_archive_cp = twitter_archive_cp.loc[twitter_archive_cp.timestamp <= '2017-08-01']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   tweet_id                    2356 non-null   int64              \n",
      " 1   in_reply_to_status_id       78 non-null     float64            \n",
      " 2   in_reply_to_user_id         78 non-null     float64            \n",
      " 3   timestamp                   2356 non-null   datetime64[ns, UTC]\n",
      " 4   source                      2356 non-null   object             \n",
      " 5   text                        2356 non-null   object             \n",
      " 6   retweeted_status_id         181 non-null    float64            \n",
      " 7   retweeted_status_user_id    181 non-null    float64            \n",
      " 8   retweeted_status_timestamp  181 non-null    object             \n",
      " 9   expanded_urls               2297 non-null   object             \n",
      " 10  rating_numerator            2356 non-null   int64              \n",
      " 11  rating_denominator          2356 non-null   int64              \n",
      " 12  name                        2356 non-null   object             \n",
      " 13  doggo                       2356 non-null   object             \n",
      " 14  floofer                     2356 non-null   object             \n",
      " 15  pupper                      2356 non-null   object             \n",
      " 16  puppo                       2356 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(4), int64(3), object(9)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check datatype\n",
    "twitter_archive_cp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data in datetime to make sure not beyond 2017, Aug 1st.\n",
    "(twitter_archive_cp.timestamp > '2017-08-01').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define: Rating denominator is equal to 0\n",
    "- Rating denominator should not be equal to 0, if exist, need to be excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the record out of data\n",
    "twitter_archive_cp = twitter_archive_cp[twitter_archive_cp.rating_denominator != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the result\n",
    "(twitter_archive_cp.rating_denominator == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Column expanded_urls has more than 2 links, one in which is not twitter link or duplicated links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb20087286067b059c4db6a2e5ff65a3149edd9c18e3f3175bd0c00233a13bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
