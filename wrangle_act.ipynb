{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import requests as re\n",
    "import os\n",
    "import tweepy as tp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read WeRateDogs Twitter archive file on hand\n",
    "twitter_archive = pd.read_csv(r'C:\\Users\\DE\\Documents\\Data wrangling_Udacity\\twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write file tsv containing images\n",
    "path = os.getcwd() # get the current path\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = re.get(url)\n",
    "if not os.path.exists(url.split('/')[-1]):\n",
    "    with open(os.path.join(path, url.split('/')[-1]), mode = 'wb') as file:\n",
    "        file.write(response.content)\n",
    "        \n",
    "# read image prediction tsv file into dataframe\n",
    "image_prediction = pd.read_csv(r'C:\\Users\\DE\\Documents\\Data wrangling_Udacity\\image-predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# omit keys from submission to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'trwzMEOtXrAFiyJRW2hZVqA5c'\n",
    "consumer_secret = 'JVI4rTTIyccfAABQDjprAGnpsQ1CEyIWaNfXSTfVei9V5mxVLv'\n",
    "access_token = '1576941143874760704-dhdfW9p2fDUxO2bkxKGOBnTAa2mxZZ'\n",
    "access_secret = 'IIuy2YQxQheg8zG3HN9C9czHAenjpn7rC7AALpctel1ov'\n",
    "\n",
    "auth = tp.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tp.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid gather data again in case the file is ready\n",
    "if not os.path.exists('tweet_json.txt'):\n",
    "    # list twitter id into array to query Twitter API for additional information\n",
    "    list_id = twitter_archive.tweet_id.values\n",
    "\n",
    "    # store each tweet's entire set of JSON data in a file called tweet_json.txt file\n",
    "    fails_dict = {}\n",
    "    with open('tweet_json.txt', 'w', encoding = 'utf-8') as f: \n",
    "        for id in list_id: \n",
    "            try: \n",
    "                tweet = api.get_status(id, tweet_mode='extended')\n",
    "                json.dump(tweet._json, f)\n",
    "                f.write('\\n')\n",
    "            except tp.errors.TweepyException as e: \n",
    "                fails_dict[id] = e\n",
    "                pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tweet_json.txt line by line into dataframe \n",
    "# with tweet ID, retweet count, favorite count\n",
    "df_list = []\n",
    "with open('tweet_json.txt', 'r', encoding = 'utf-8') as f:\n",
    "    for count, line in enumerate(f): \n",
    "        tweet_id = json.loads(line)['id']\n",
    "        retweet_count = json.loads(line)['retweet_count']\n",
    "        favorite_count = json.loads(line)['favorite_count']\n",
    "        df_list.append({'tweet_id': tweet_id, \n",
    "        'retweet_count': retweet_count, \n",
    "        'favorite_count': favorite_count})\n",
    "\n",
    "tweet_api = pd.DataFrame(df_list, columns = ['tweet_id', 'retweet_count', 'favorite_count'])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change datatype timestamp from string into datetime to exclude tweets beyond August 1st, 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   int64  \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check datatype of timestamp column\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2017-08-01 16:23:56 +0000\n",
       "1       2017-08-01 00:17:27 +0000\n",
       "2       2017-07-31 00:18:03 +0000\n",
       "3       2017-07-30 15:58:51 +0000\n",
       "4       2017-07-29 16:00:24 +0000\n",
       "                  ...            \n",
       "2351    2015-11-16 00:24:50 +0000\n",
       "2352    2015-11-16 00:04:52 +0000\n",
       "2353    2015-11-15 23:21:54 +0000\n",
       "2354    2015-11-15 23:05:30 +0000\n",
       "2355    2015-11-15 22:32:08 +0000\n",
       "Name: timestamp, Length: 2356, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data format\n",
    "twitter_archive.timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rating denominator is equal to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>835246439529840640</td>\n",
       "      <td>8.352460e+17</td>\n",
       "      <td>26259576.0</td>\n",
       "      <td>2017-02-24 21:54:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>@jonnysun @Lin_Manuel ok jomny I know you're e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "313  835246439529840640           8.352460e+17           26259576.0   \n",
       "\n",
       "                     timestamp  \\\n",
       "313  2017-02-24 21:54:03 +0000   \n",
       "\n",
       "                                                source  \\\n",
       "313  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                  text  retweeted_status_id  \\\n",
       "313  @jonnysun @Lin_Manuel ok jomny I know you're e...                  NaN   \n",
       "\n",
       "     retweeted_status_user_id retweeted_status_timestamp expanded_urls  \\\n",
       "313                       NaN                        NaN           NaN   \n",
       "\n",
       "     rating_numerator  rating_denominator  name doggo floofer pupper puppo  \n",
       "313               960                   0  None  None    None   None  None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive[twitter_archive.rating_denominator == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Column expanded_urls has more 2 links, one in which is not twitter link or duplicated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950     https://twitter.com/dog_rates/status/752173152...\n",
       "805     https://twitter.com/dog_rates/status/772114945...\n",
       "425     https://twitter.com/dog_rates/status/782305867...\n",
       "1210    https://twitter.com/dog_rates/status/715680795...\n",
       "1173    https://twitter.com/dog_rates/status/720340705...\n",
       "592     https://twitter.com/dog_rates/status/798933969...\n",
       "687     https://twitter.com/dog_rates/status/788039637...\n",
       "277     https://twitter.com/dog_rates/status/840370681...\n",
       "2288    https://twitter.com/dog_rates/status/667176164...\n",
       "1335    https://twitter.com/dog_rates/status/705239209...\n",
       "Name: expanded_urls, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly check the data format in expanded_urls\n",
    "twitter_archive.expanded_urls.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.gofundme.com/help-my-baby-sierra-get-better,https://twitter.com/dog_rates/status/873213775632977920/photo/1,https://twitter.com/dog_rates/status/873213775632977920/photo/1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check random data to see expanded_urls\n",
    "twitter_archive.at[98, 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Column name contains wrong names, convert None into NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323          None\n",
       "1248         None\n",
       "1349         None\n",
       "1042         None\n",
       "1450         None\n",
       "1783         None\n",
       "360           Mia\n",
       "1235        Sunny\n",
       "817     Sebastian\n",
       "1908       Bailey\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special character is not the right name is: a, the, ...\n",
    "twitter_archive.name.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tweet_ID = 740373189193256964 the dog has the rating is 14/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 740373189193256964].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Tweet_ID = 810984652412424192 the dog does not have the rating yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.gofundme.com/sams-smile,https://twitter.com/dog_rates/status/810984652412424192/photo/1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "# this tweet_id is not displayed -  24/7 not the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 810984652412424192].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Tweet_ID = 722974582966214656 the dog has the rating is 13/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/722974582966214656/photo/1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 722974582966214656].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Tweet_ID = 666287406224695296 the dog has the rating is 9/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/666287406224695296/photo/1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data based on url by visual assessment to see the rating\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 666287406224695296].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Tweet_ID = 775096608509886464 does not exist, it is a duplication of Tweet_ID = 740373189193256964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1,https://twitter.com/dog_rates/status/740373189193256964/photo/1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the id in the url is 740373189193256964 not 775096608509886464\n",
    "twitter_archive.at[twitter_archive[twitter_archive.tweet_id == 775096608509886464].index.values[0], 'expanded_urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove data in twitter-archive-enhancement.csv for matching with the image_prediction.tsv - only data not beyond August 1st, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Match image prediction columns in image_prediction.tsv to define dog tweet_id and columns retweet count and favorite count in tweet_api for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "twitter_archive_cp = twitter_archive.copy()\n",
    "image_prediction_cp = image_prediction.copy()\n",
    "tweet_api_cp = tweet_api.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Change datatype timestamp from string into datetime to exclude tweets beyond August 1st, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype\n",
    "twitter_archive_cp.timestamp = pd.to_datetime(twitter_archive_cp.timestamp)\n",
    "\n",
    "# exclude data with timestamp beyond August 1st, 2017\n",
    "twitter_archive_cp = twitter_archive_cp.loc[twitter_archive_cp.timestamp <= '2017-08-01']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2354 entries, 2 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   tweet_id                    2354 non-null   int64              \n",
      " 1   in_reply_to_status_id       78 non-null     float64            \n",
      " 2   in_reply_to_user_id         78 non-null     float64            \n",
      " 3   timestamp                   2354 non-null   datetime64[ns, UTC]\n",
      " 4   source                      2354 non-null   object             \n",
      " 5   text                        2354 non-null   object             \n",
      " 6   retweeted_status_id         181 non-null    float64            \n",
      " 7   retweeted_status_user_id    181 non-null    float64            \n",
      " 8   retweeted_status_timestamp  181 non-null    object             \n",
      " 9   expanded_urls               2295 non-null   object             \n",
      " 10  rating_numerator            2354 non-null   int64              \n",
      " 11  rating_denominator          2354 non-null   int64              \n",
      " 12  name                        2354 non-null   object             \n",
      " 13  doggo                       2354 non-null   object             \n",
      " 14  floofer                     2354 non-null   object             \n",
      " 15  pupper                      2354 non-null   object             \n",
      " 16  puppo                       2354 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(4), int64(3), object(9)\n",
      "memory usage: 331.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check datatype\n",
    "twitter_archive_cp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data in datetime to make sure not beyond 2017, Aug 1st.\n",
    "(twitter_archive_cp.timestamp > '2017-08-01').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define: Rating denominator is equal to 0\n",
    "- Rating denominator should not be equal to 0, if exist, need to be excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the record out of data\n",
    "twitter_archive_cp = twitter_archive_cp[twitter_archive_cp.rating_denominator != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the result\n",
    "(twitter_archive_cp.rating_denominator == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Column expanded_urls has more than 2 links, one in which is not twitter link or duplicated links\n",
    "- Tweet id has duplicated urls \n",
    "- Tweet id has other link apart from Twitter link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweet_id having more than 1 url 82.0\n",
      "number of tweet_id having more than 2 urls 0.0\n"
     ]
    }
   ],
   "source": [
    "# create a serie to check url different than twitter url\n",
    "arr = twitter_archive_cp['expanded_urls'].apply(lambda x: len(set(x.split(','))) if str(x) != 'nan' else x)\n",
    "# check the rows that number of tweet_id having more than 1 url\n",
    "print('number of tweet_id having more than 1 url', arr[(arr > 1)].sum()) \n",
    "print('number of tweet_id having more than 2 urls', arr[(arr > 2)].sum())\n",
    "\n",
    "# apply for tweet_id having duplicated urls\n",
    "getOnelink = lambda x: list(set(x.split(',')))[0] if (str(x) != 'nan' and len(list(set(x.split(',')))) == 1) else x\n",
    "twitter_archive_cp['expanded_urls'] = twitter_archive_cp['expanded_urls'].apply(lambda x: getOnelink(x))\n",
    "\n",
    "# apply for tweet_id having more than 1 unique url\n",
    "def getTwitter(a): \n",
    "    return list(filter(lambda x: re.findall(r'.+twitter.com.+', x), a))[0]\n",
    "\n",
    "getTwitterlink = lambda x: getTwitter(x.split(',')) if (str(x) != 'nan' and len(list(set(x.split(',')))) > 1) else x\n",
    "twitter_archive_cp['expanded_urls'] = twitter_archive_cp['expanded_urls'].apply(lambda x: getTwitterlink(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = twitter_archive_cp['expanded_urls'].apply(lambda x: len(x.split(',')) if str(x) != 'nan' else x)\n",
    "\n",
    "(arr >1).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('data_wrangling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "757bb194e254ecf1a0e3894dc0da6672b47aebc0c507cccb4239d869fbe1032a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
